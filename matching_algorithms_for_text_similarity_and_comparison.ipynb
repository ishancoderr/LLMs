{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNji+wyLDhkljwfhjflkg0j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishancoderr/LLMs/blob/main/matching_algorithms_for_text_similarity_and_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIYsAfIhKlwR",
        "outputId": "a590405c-c33e-4204-d3eb-91f168fafc38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textdistance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ziLMecwZ3xZ",
        "outputId": "09c94e3e-74fa-44e2-dea9-13598e638d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textdistance\n",
            "  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Downloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: textdistance\n",
            "Successfully installed textdistance-4.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from rapidfuzz import fuzz\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import textdistance\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Example strings for comparison (20 different pairs)\n",
        "strings = [\n",
        "    (\"United State of America\", \"USA\"),\n",
        "    (\"Ishan Weerakoon\", \"Ishan Thathsara Weerakoon\"),\n",
        "    (\"New York\", \"NY\"),\n",
        "    (\"California\", \"CA\"),\n",
        "    (\"Machine Learning\", \"AI\"),\n",
        "    (\"Artificial Intelligence\", \"Machine Learning\"),\n",
        "    (\"Python Programming\", \"Java Programming\"),\n",
        "    (\"Deep Learning\", \"Neural Networks\"),\n",
        "    (\"Geospatial Data\", \"GIS\"),\n",
        "    (\"Data Science\", \"Big Data\"),\n",
        "    (\"Data Visualization\", \"Data Analytics\"),\n",
        "    (\"Natural Language Processing\", \"Speech Recognition\"),\n",
        "    (\"Computer Vision\", \"Image Processing\"),\n",
        "    (\"Blockchain\", \"Cryptocurrency\"),\n",
        "    (\"Cloud Computing\", \"Distributed Systems\"),\n",
        "    (\"Internet of Things\", \"IoT\"),\n",
        "    (\"Cybersecurity\", \"Information Security\"),\n",
        "    (\"Software Engineering\", \"System Development\"),\n",
        "    (\"Quantum Computing\", \"Quantum Algorithms\"),\n",
        "    (\"Robotics\", \"Automation\")\n",
        "]\n",
        "\n",
        "# Load SentenceTransformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Measure time and compare models for each string pair\n",
        "for text1, text2 in strings:\n",
        "    print(f\"\\nComparing: {text1} vs {text2}\")\n",
        "\n",
        "    # **RapidFuzz**\n",
        "    start = time.time()\n",
        "    fuzzy_score = fuzz.ratio(text1, text2)\n",
        "    rapidfuzz_time = time.time() - start\n",
        "    print(f\"RapidFuzz Score: {fuzzy_score} | Time: {rapidfuzz_time:.6f} sec\")\n",
        "\n",
        "    # **Cosine Similarity with TF-IDF**\n",
        "    start = time.time()\n",
        "    documents = [text1, text2]\n",
        "    tfidf = TfidfVectorizer()\n",
        "    vectors = tfidf.fit_transform(documents)\n",
        "    cosine_sim = cosine_similarity(vectors[0], vectors[1])\n",
        "    cosine_time = time.time() - start\n",
        "    print(f\"Cosine Similarity (TF-IDF): {cosine_sim[0][0]} | Time: {cosine_time:.6f} sec\")\n",
        "\n",
        "    # **TextDistance (Damerau-Levenshtein)**\n",
        "    start = time.time()\n",
        "    distance = textdistance.damerau_levenshtein.normalized_similarity(text1, text2)\n",
        "    textdistance_time = time.time() - start\n",
        "    print(f\"TextDistance Similarity: {distance} | Time: {textdistance_time:.6f} sec\")\n",
        "\n",
        "    # **SentenceTransformers (Semantic Similarity)**\n",
        "    start = time.time()\n",
        "    emb1 = model.encode(text1)\n",
        "    emb2 = model.encode(text2)\n",
        "    similarity = util.cos_sim(emb1, emb2)\n",
        "    sentence_transformers_time = time.time() - start\n",
        "    print(f\"Semantic Similarity: {similarity.item()} | Time: {sentence_transformers_time:.6f} sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrXeZAOdcciL",
        "outputId": "14d11bd8-dceb-4b55-c91d-aa4e84bc1646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparing: United State of America vs USA\n",
            "RapidFuzz Score: 23.076923076923073 | Time: 0.000018 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.006275 sec\n",
            "TextDistance Similarity: 0.13043478260869568 | Time: 0.000094 sec\n",
            "Semantic Similarity: 0.6735268831253052 | Time: 0.056481 sec\n",
            "\n",
            "Comparing: Ishan Weerakoon vs Ishan Thathsara Weerakoon\n",
            "RapidFuzz Score: 75.0 | Time: 0.000012 sec\n",
            "Cosine Similarity (TF-IDF): 0.7092972666062739 | Time: 0.006552 sec\n",
            "TextDistance Similarity: 0.6 | Time: 0.000074 sec\n",
            "Semantic Similarity: 0.9155293703079224 | Time: 0.098614 sec\n",
            "\n",
            "Comparing: New York vs NY\n",
            "RapidFuzz Score: 40.0 | Time: 0.000012 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.011745 sec\n",
            "TextDistance Similarity: 0.25 | Time: 0.000077 sec\n",
            "Semantic Similarity: 0.8770714402198792 | Time: 0.092146 sec\n",
            "\n",
            "Comparing: California vs CA\n",
            "RapidFuzz Score: 16.666666666666664 | Time: 0.000014 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.004665 sec\n",
            "TextDistance Similarity: 0.09999999999999998 | Time: 0.000070 sec\n",
            "Semantic Similarity: 0.8182401657104492 | Time: 0.048297 sec\n",
            "\n",
            "Comparing: Machine Learning vs AI\n",
            "RapidFuzz Score: 0.0 | Time: 0.000014 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.004726 sec\n",
            "TextDistance Similarity: 0.0 | Time: 0.000070 sec\n",
            "Semantic Similarity: 0.5463714599609375 | Time: 0.048506 sec\n",
            "\n",
            "Comparing: Artificial Intelligence vs Machine Learning\n",
            "RapidFuzz Score: 30.76923076923077 | Time: 0.000015 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.004721 sec\n",
            "TextDistance Similarity: 0.17391304347826086 | Time: 0.000080 sec\n",
            "Semantic Similarity: 0.7034627199172974 | Time: 0.127852 sec\n",
            "\n",
            "Comparing: Python Programming vs Java Programming\n",
            "RapidFuzz Score: 70.58823529411764 | Time: 0.000012 sec\n",
            "Cosine Similarity (TF-IDF): 0.33609692727625756 | Time: 0.011443 sec\n",
            "TextDistance Similarity: 0.6666666666666667 | Time: 0.000077 sec\n",
            "Semantic Similarity: 0.512253999710083 | Time: 0.050908 sec\n",
            "\n",
            "Comparing: Deep Learning vs Neural Networks\n",
            "RapidFuzz Score: 28.57142857142857 | Time: 0.000013 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.006122 sec\n",
            "TextDistance Similarity: 0.19999999999999996 | Time: 0.000070 sec\n",
            "Semantic Similarity: 0.7546783685684204 | Time: 0.048669 sec\n",
            "\n",
            "Comparing: Geospatial Data vs GIS\n",
            "RapidFuzz Score: 11.111111111111116 | Time: 0.000013 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.007057 sec\n",
            "TextDistance Similarity: 0.06666666666666665 | Time: 0.000074 sec\n",
            "Semantic Similarity: 0.29592832922935486 | Time: 0.062684 sec\n",
            "\n",
            "Comparing: Data Science vs Big Data\n",
            "RapidFuzz Score: 40.0 | Time: 0.000015 sec\n",
            "Cosine Similarity (TF-IDF): 0.33609692727625756 | Time: 0.004785 sec\n",
            "TextDistance Similarity: 0.08333333333333337 | Time: 0.000072 sec\n",
            "Semantic Similarity: 0.6253911256790161 | Time: 0.054726 sec\n",
            "\n",
            "Comparing: Data Visualization vs Data Analytics\n",
            "RapidFuzz Score: 56.25 | Time: 0.000014 sec\n",
            "Cosine Similarity (TF-IDF): 0.33609692727625756 | Time: 0.004827 sec\n",
            "TextDistance Similarity: 0.5 | Time: 0.000074 sec\n",
            "Semantic Similarity: 0.5603060126304626 | Time: 0.050102 sec\n",
            "\n",
            "Comparing: Natural Language Processing vs Speech Recognition\n",
            "RapidFuzz Score: 22.22222222222222 | Time: 0.000024 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.004621 sec\n",
            "TextDistance Similarity: 0.14814814814814814 | Time: 0.000073 sec\n",
            "Semantic Similarity: 0.4481136202812195 | Time: 0.055537 sec\n",
            "\n",
            "Comparing: Computer Vision vs Image Processing\n",
            "RapidFuzz Score: 38.70967741935484 | Time: 0.000014 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.004604 sec\n",
            "TextDistance Similarity: 0.1875 | Time: 0.000074 sec\n",
            "Semantic Similarity: 0.6832850575447083 | Time: 0.060836 sec\n",
            "\n",
            "Comparing: Blockchain vs Cryptocurrency\n",
            "RapidFuzz Score: 25.0 | Time: 0.000014 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.004786 sec\n",
            "TextDistance Similarity: 0.1428571428571429 | Time: 0.000072 sec\n",
            "Semantic Similarity: 0.6347827911376953 | Time: 0.063851 sec\n",
            "\n",
            "Comparing: Cloud Computing vs Distributed Systems\n",
            "RapidFuzz Score: 23.529411764705888 | Time: 0.000013 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.006420 sec\n",
            "TextDistance Similarity: 0.10526315789473684 | Time: 0.000071 sec\n",
            "Semantic Similarity: 0.492274671792984 | Time: 0.050488 sec\n",
            "\n",
            "Comparing: Internet of Things vs IoT\n",
            "RapidFuzz Score: 28.57142857142857 | Time: 0.000014 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.004872 sec\n",
            "TextDistance Similarity: 0.16666666666666663 | Time: 0.000074 sec\n",
            "Semantic Similarity: 0.7892196178436279 | Time: 0.071434 sec\n",
            "\n",
            "Comparing: Cybersecurity vs Information Security\n",
            "RapidFuzz Score: 48.484848484848484 | Time: 0.000014 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.005356 sec\n",
            "TextDistance Similarity: 0.4 | Time: 0.000073 sec\n",
            "Semantic Similarity: 0.6542270183563232 | Time: 0.057036 sec\n",
            "\n",
            "Comparing: Software Engineering vs System Development\n",
            "RapidFuzz Score: 36.8421052631579 | Time: 0.000014 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.006421 sec\n",
            "TextDistance Similarity: 0.19999999999999996 | Time: 0.000072 sec\n",
            "Semantic Similarity: 0.5478730201721191 | Time: 0.091683 sec\n",
            "\n",
            "Comparing: Quantum Computing vs Quantum Algorithms\n",
            "RapidFuzz Score: 57.14285714285714 | Time: 0.000014 sec\n",
            "Cosine Similarity (TF-IDF): 0.33609692727625756 | Time: 0.012398 sec\n",
            "TextDistance Similarity: 0.5 | Time: 0.000078 sec\n",
            "Semantic Similarity: 0.8476635813713074 | Time: 0.105568 sec\n",
            "\n",
            "Comparing: Robotics vs Automation\n",
            "RapidFuzz Score: 33.333333333333336 | Time: 0.000014 sec\n",
            "Cosine Similarity (TF-IDF): 0.0 | Time: 0.017994 sec\n",
            "TextDistance Similarity: 0.30000000000000004 | Time: 0.000082 sec\n",
            "Semantic Similarity: 0.48890024423599243 | Time: 0.058469 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Comparison Summary\n",
        "\n",
        "#### **RapidFuzz**:\n",
        "- **Best for speed with short, direct strings**.\n",
        "- This model is ideal when **speed** is the top priority, especially when dealing with **short, direct strings**. It provides fast comparisons and reasonable similarity scores for simpler text matches.\n",
        "\n",
        "#### **Cosine Similarity (TF-IDF)**:\n",
        "- **Best for comparing documents and word significance**.\n",
        "- This model is suitable when comparing **larger, document-like content**. It focuses on capturing the **occurrence and significance** of words and is more effective in scenarios where document-level comparisons are necessary.\n",
        "\n",
        "#### **TextDistance (Edit Distance)**:\n",
        "- **Best for handling minor text differences or typos**.\n",
        "- TextDistance is effective in scenarios where there are **minor variations or typos** between two strings. It measures the similarity based on how many edits (insertions, deletions, substitutions) are needed to convert one string into another.\n",
        "\n",
        "#### **Semantic Similarity (Sentence Transformers)**:\n",
        "- **Best for capturing semantic meaning**.\n",
        "- This method excels at comparing strings with different wordings but **similar meanings**. It's the most **robust model for semantic similarity**, providing meaningful similarity scores even when phrases differ significantly in structure or vocabulary. However, it is **slower** than the other models."
      ],
      "metadata": {
        "id": "xYwcdXZHj9Kk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Elastic search**"
      ],
      "metadata": {
        "id": "fTbioOJ_lSLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install elasticsearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JExKZ4hWgDW",
        "outputId": "9d675327-74f4-41da-e16c-e19e8491afbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting elasticsearch\n",
            "  Downloading elasticsearch-8.17.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting elastic-transport<9,>=8.15.1 (from elasticsearch)\n",
            "  Downloading elastic_transport-8.17.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2024.12.14)\n",
            "Downloading elasticsearch-8.17.0-py3-none-any.whl (571 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.2/571.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading elastic_transport-8.17.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: elastic-transport, elasticsearch\n",
            "Successfully installed elastic-transport-8.17.0 elasticsearch-8.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7NKgrdyTZfKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "import random\n",
        "\n",
        "client = Elasticsearch(\n",
        "    \"https://my-elasticsearch-project-dd725e.es.eu-west-1.aws.elastic.cloud:443\",\n",
        "    api_key=\"\"\n",
        ")\n",
        "\n",
        "index_name = \"search-yn0c\"\n",
        "\n",
        "mappings = {\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"text\": {\n",
        "                \"type\": \"text\"  # This is for full-text search\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create the index\n",
        "if not client.indices.exists(index=index_name):\n",
        "    client.indices.create(index=index_name, body=mappings)\n",
        "    print(f\"Index '{index_name}' created.\")\n",
        "else:\n",
        "    print(f\"Index '{index_name}' already exists.\")\n",
        "\n",
        "\n",
        "def generate_random_text(length=10):\n",
        "    words = [\"sample\", \"text\", \"testing\", \"example\", \"Elasticsearch\", \"match\", \"full-text\", \"search\", \"ishan\",\"focus\"]\n",
        "    return \" \".join(random.choices(words, k=length))\n",
        "\n",
        "documents = [{\"text\": generate_random_text()} for _ in range(200)]\n",
        "\n",
        "# Index the documents\n",
        "for i, doc in enumerate(documents):\n",
        "    client.index(index=index_name, id=i, body=doc)\n",
        "    print(f\"Document {i} indexed.\")\n",
        "\n",
        "# Perform a text match query\n",
        "query = {\n",
        "    \"query\": {\n",
        "        \"match\": {\n",
        "            \"text\": \"This is a ft sample text for testing\"  # The text to search for\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Execute the search query\n",
        "response = client.search(index=index_name, body=query)\n",
        "\n",
        "# Print the results\n",
        "print(\"\\nSearch Results:\")\n",
        "for hit in response[\"hits\"][\"hits\"]:\n",
        "    print(f\"Text: {hit['_source']['text']} | Score: {hit['_score']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHbSroByW0Iw",
        "outputId": "8b6985c3-1fbd-4519-c3a7-2f1bb5461320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 'search-yn0c' already exists.\n",
            "Document 0 indexed.\n",
            "Document 1 indexed.\n",
            "Document 2 indexed.\n",
            "Document 3 indexed.\n",
            "Document 4 indexed.\n",
            "Document 5 indexed.\n",
            "Document 6 indexed.\n",
            "Document 7 indexed.\n",
            "Document 8 indexed.\n",
            "Document 9 indexed.\n",
            "Document 10 indexed.\n",
            "Document 11 indexed.\n",
            "Document 12 indexed.\n",
            "Document 13 indexed.\n",
            "Document 14 indexed.\n",
            "Document 15 indexed.\n",
            "Document 16 indexed.\n",
            "Document 17 indexed.\n",
            "Document 18 indexed.\n",
            "Document 19 indexed.\n",
            "Document 20 indexed.\n",
            "Document 21 indexed.\n",
            "Document 22 indexed.\n",
            "Document 23 indexed.\n",
            "Document 24 indexed.\n",
            "Document 25 indexed.\n",
            "Document 26 indexed.\n",
            "Document 27 indexed.\n",
            "Document 28 indexed.\n",
            "Document 29 indexed.\n",
            "Document 30 indexed.\n",
            "Document 31 indexed.\n",
            "Document 32 indexed.\n",
            "Document 33 indexed.\n",
            "Document 34 indexed.\n",
            "Document 35 indexed.\n",
            "Document 36 indexed.\n",
            "Document 37 indexed.\n",
            "Document 38 indexed.\n",
            "Document 39 indexed.\n",
            "Document 40 indexed.\n",
            "Document 41 indexed.\n",
            "Document 42 indexed.\n",
            "Document 43 indexed.\n",
            "Document 44 indexed.\n",
            "Document 45 indexed.\n",
            "Document 46 indexed.\n",
            "Document 47 indexed.\n",
            "Document 48 indexed.\n",
            "Document 49 indexed.\n",
            "Document 50 indexed.\n",
            "Document 51 indexed.\n",
            "Document 52 indexed.\n",
            "Document 53 indexed.\n",
            "Document 54 indexed.\n",
            "Document 55 indexed.\n",
            "Document 56 indexed.\n",
            "Document 57 indexed.\n",
            "Document 58 indexed.\n",
            "Document 59 indexed.\n",
            "Document 60 indexed.\n",
            "Document 61 indexed.\n",
            "Document 62 indexed.\n",
            "Document 63 indexed.\n",
            "Document 64 indexed.\n",
            "Document 65 indexed.\n",
            "Document 66 indexed.\n",
            "Document 67 indexed.\n",
            "Document 68 indexed.\n",
            "Document 69 indexed.\n",
            "Document 70 indexed.\n",
            "Document 71 indexed.\n",
            "Document 72 indexed.\n",
            "Document 73 indexed.\n",
            "Document 74 indexed.\n",
            "Document 75 indexed.\n",
            "Document 76 indexed.\n",
            "Document 77 indexed.\n",
            "Document 78 indexed.\n",
            "Document 79 indexed.\n",
            "Document 80 indexed.\n",
            "Document 81 indexed.\n",
            "Document 82 indexed.\n",
            "Document 83 indexed.\n",
            "Document 84 indexed.\n",
            "Document 85 indexed.\n",
            "Document 86 indexed.\n",
            "Document 87 indexed.\n",
            "Document 88 indexed.\n",
            "Document 89 indexed.\n",
            "Document 90 indexed.\n",
            "Document 91 indexed.\n",
            "Document 92 indexed.\n",
            "Document 93 indexed.\n",
            "Document 94 indexed.\n",
            "Document 95 indexed.\n",
            "Document 96 indexed.\n",
            "Document 97 indexed.\n",
            "Document 98 indexed.\n",
            "Document 99 indexed.\n",
            "Document 100 indexed.\n",
            "Document 101 indexed.\n",
            "Document 102 indexed.\n",
            "Document 103 indexed.\n",
            "Document 104 indexed.\n",
            "Document 105 indexed.\n",
            "Document 106 indexed.\n",
            "Document 107 indexed.\n",
            "Document 108 indexed.\n",
            "Document 109 indexed.\n",
            "Document 110 indexed.\n",
            "Document 111 indexed.\n",
            "Document 112 indexed.\n",
            "Document 113 indexed.\n",
            "Document 114 indexed.\n",
            "Document 115 indexed.\n",
            "Document 116 indexed.\n",
            "Document 117 indexed.\n",
            "Document 118 indexed.\n",
            "Document 119 indexed.\n",
            "Document 120 indexed.\n",
            "Document 121 indexed.\n",
            "Document 122 indexed.\n",
            "Document 123 indexed.\n",
            "Document 124 indexed.\n",
            "Document 125 indexed.\n",
            "Document 126 indexed.\n",
            "Document 127 indexed.\n",
            "Document 128 indexed.\n",
            "Document 129 indexed.\n",
            "Document 130 indexed.\n",
            "Document 131 indexed.\n",
            "Document 132 indexed.\n",
            "Document 133 indexed.\n",
            "Document 134 indexed.\n",
            "Document 135 indexed.\n",
            "Document 136 indexed.\n",
            "Document 137 indexed.\n",
            "Document 138 indexed.\n",
            "Document 139 indexed.\n",
            "Document 140 indexed.\n",
            "Document 141 indexed.\n",
            "Document 142 indexed.\n",
            "Document 143 indexed.\n",
            "Document 144 indexed.\n",
            "Document 145 indexed.\n",
            "Document 146 indexed.\n",
            "Document 147 indexed.\n",
            "Document 148 indexed.\n",
            "Document 149 indexed.\n",
            "Document 150 indexed.\n",
            "Document 151 indexed.\n",
            "Document 152 indexed.\n",
            "Document 153 indexed.\n",
            "Document 154 indexed.\n",
            "Document 155 indexed.\n",
            "Document 156 indexed.\n",
            "Document 157 indexed.\n",
            "Document 158 indexed.\n",
            "Document 159 indexed.\n",
            "Document 160 indexed.\n",
            "Document 161 indexed.\n",
            "Document 162 indexed.\n",
            "Document 163 indexed.\n",
            "Document 164 indexed.\n",
            "Document 165 indexed.\n",
            "Document 166 indexed.\n",
            "Document 167 indexed.\n",
            "Document 168 indexed.\n",
            "Document 169 indexed.\n",
            "Document 170 indexed.\n",
            "Document 171 indexed.\n",
            "Document 172 indexed.\n",
            "Document 173 indexed.\n",
            "Document 174 indexed.\n",
            "Document 175 indexed.\n",
            "Document 176 indexed.\n",
            "Document 177 indexed.\n",
            "Document 178 indexed.\n",
            "Document 179 indexed.\n",
            "Document 180 indexed.\n",
            "Document 181 indexed.\n",
            "Document 182 indexed.\n",
            "Document 183 indexed.\n",
            "Document 184 indexed.\n",
            "Document 185 indexed.\n",
            "Document 186 indexed.\n",
            "Document 187 indexed.\n",
            "Document 188 indexed.\n",
            "Document 189 indexed.\n",
            "Document 190 indexed.\n",
            "Document 191 indexed.\n",
            "Document 192 indexed.\n",
            "Document 193 indexed.\n",
            "Document 194 indexed.\n",
            "Document 195 indexed.\n",
            "Document 196 indexed.\n",
            "Document 197 indexed.\n",
            "Document 198 indexed.\n",
            "Document 199 indexed.\n",
            "\n",
            "Search Results:\n",
            "Text: search sample sample testing text match full-text sample testing testing | Score: 1.5817614\n",
            "Text: testing example text ishan sample sample sample Elasticsearch focus testing | Score: 1.5478563\n",
            "Text: Elasticsearch text example testing sample sample ishan focus testing sample | Score: 1.5478563\n",
            "Text: sample match sample sample full-text match testing testing example sample | Score: 1.4818813\n",
            "Text: testing match sample text testing search sample testing full-text text | Score: 1.4598653\n",
            "Text: text sample sample example search sample sample full-text full-text testing | Score: 1.4225227\n",
            "Text: sample sample text testing example ishan search Elasticsearch testing match | Score: 1.4049989\n",
            "Text: search testing focus text testing Elasticsearch full-text testing text sample | Score: 1.3977894\n",
            "Text: testing focus sample testing search match full-text text match testing | Score: 1.3824028\n",
            "Text: sample sample testing full-text example text match sample Elasticsearch search | Score: 1.3755876\n"
          ]
        }
      ]
    }
  ]
}